{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"hatch.linewidth\" on line 54 in\n",
      "/home/gpleiss/.dotfiles/matplotlibrc.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "train_x = Variable(torch.linspace(0, 1, 1001)).cuda()\n",
    "train_y = Variable(torch.sign(torch.cos(train_x.data * (8 * math.pi)))).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from gpytorch.kernels import RBFKernel, GridInterpolationKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood, BernoulliLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable\n",
    "gpytorch.functions.use_toeplitz = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GPClassificationModel(gpytorch.models.GridInducingVariationalGP):\n",
    "    def __init__(self):\n",
    "        super(GPClassificationModel, self).__init__(grid_size=100, grid_bounds=[(0, 1)])\n",
    "        self.mean_module = ConstantMean(constant_bounds=[-1e-5,1e-5])\n",
    "        self.covar_module = RBFKernel(log_lengthscale_bounds=(-5, 6))\n",
    "        self.register_parameter('log_outputscale', nn.Parameter(torch.Tensor([0])), bounds=(-5,6))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        covar_x = covar_x.mul(self.log_outputscale.exp())\n",
    "        latent_pred = GaussianRandomVariable(mean_x, covar_x)\n",
    "        return latent_pred\n",
    "\n",
    "model = GPClassificationModel().cuda()\n",
    "likelihood = BernoulliLikelihood().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 475.924   log_lengthscale: 0.000\n",
      "Iter 2/200 - Loss: 379.204   log_lengthscale: -0.100\n",
      "Iter 3/200 - Loss: 271.253   log_lengthscale: -0.185\n",
      "Iter 4/200 - Loss: 225.627   log_lengthscale: -0.259\n",
      "Iter 5/200 - Loss: 164.497   log_lengthscale: -0.340\n",
      "Iter 6/200 - Loss: 110.020   log_lengthscale: -0.420\n",
      "Iter 7/200 - Loss: 85.413   log_lengthscale: -0.492\n",
      "Iter 8/200 - Loss: 44.792   log_lengthscale: -0.562\n",
      "Iter 9/200 - Loss: 41.101   log_lengthscale: -0.632\n",
      "Iter 10/200 - Loss: 24.976   log_lengthscale: -0.710\n",
      "Iter 11/200 - Loss: 18.955   log_lengthscale: -0.787\n",
      "Iter 12/200 - Loss: 9.097   log_lengthscale: -0.863\n",
      "Iter 13/200 - Loss: 7.817   log_lengthscale: -0.936\n",
      "Iter 14/200 - Loss: 5.278   log_lengthscale: -1.016\n",
      "Iter 15/200 - Loss: 7.580   log_lengthscale: -1.092\n",
      "Iter 16/200 - Loss: 9.917   log_lengthscale: -1.168\n",
      "Iter 17/200 - Loss: 7.281   log_lengthscale: -1.241\n",
      "Iter 18/200 - Loss: 16.274   log_lengthscale: -1.311\n",
      "Iter 19/200 - Loss: 12.352   log_lengthscale: -1.379\n",
      "Iter 20/200 - Loss: 12.283   log_lengthscale: -1.450\n",
      "Iter 21/200 - Loss: 13.860   log_lengthscale: -1.523\n",
      "Iter 22/200 - Loss: 13.418   log_lengthscale: -1.587\n",
      "Iter 23/200 - Loss: 7.435   log_lengthscale: -1.651\n",
      "Iter 24/200 - Loss: 3.507   log_lengthscale: -1.715\n",
      "Iter 25/200 - Loss: 4.125   log_lengthscale: -1.773\n",
      "Iter 26/200 - Loss: 2.473   log_lengthscale: -1.830\n",
      "Iter 27/200 - Loss: 3.775   log_lengthscale: -1.894\n",
      "Iter 28/200 - Loss: 2.428   log_lengthscale: -1.960\n",
      "Iter 29/200 - Loss: 2.314   log_lengthscale: -2.022\n",
      "Iter 30/200 - Loss: 2.303   log_lengthscale: -2.080\n",
      "Iter 31/200 - Loss: 1.510   log_lengthscale: -2.137\n",
      "Iter 32/200 - Loss: 1.533   log_lengthscale: -2.194\n",
      "Iter 33/200 - Loss: 1.202   log_lengthscale: -2.248\n",
      "Iter 34/200 - Loss: 1.098   log_lengthscale: -2.298\n",
      "Iter 35/200 - Loss: 1.183   log_lengthscale: -2.345\n",
      "Iter 36/200 - Loss: 0.988   log_lengthscale: -2.386\n",
      "Iter 37/200 - Loss: 1.145   log_lengthscale: -2.425\n",
      "Iter 38/200 - Loss: 1.226   log_lengthscale: -2.460\n",
      "Iter 39/200 - Loss: 0.853   log_lengthscale: -2.494\n",
      "Iter 40/200 - Loss: 1.153   log_lengthscale: -2.522\n",
      "Iter 41/200 - Loss: 1.087   log_lengthscale: -2.544\n",
      "Iter 42/200 - Loss: 1.129   log_lengthscale: -2.566\n",
      "Iter 43/200 - Loss: 0.831   log_lengthscale: -2.583\n",
      "Iter 44/200 - Loss: 1.346   log_lengthscale: -2.599\n",
      "Iter 45/200 - Loss: 0.893   log_lengthscale: -2.611\n",
      "Iter 46/200 - Loss: 1.262   log_lengthscale: -2.622\n",
      "Iter 47/200 - Loss: 0.971   log_lengthscale: -2.632\n",
      "Iter 48/200 - Loss: 0.988   log_lengthscale: -2.641\n",
      "Iter 49/200 - Loss: 1.111   log_lengthscale: -2.650\n",
      "Iter 50/200 - Loss: 0.891   log_lengthscale: -2.659\n",
      "Iter 51/200 - Loss: 1.078   log_lengthscale: -2.667\n",
      "Iter 52/200 - Loss: 1.054   log_lengthscale: -2.675\n",
      "Iter 53/200 - Loss: 1.306   log_lengthscale: -2.682\n",
      "Iter 54/200 - Loss: 1.013   log_lengthscale: -2.685\n",
      "Iter 55/200 - Loss: 0.966   log_lengthscale: -2.685\n",
      "Iter 56/200 - Loss: 1.070   log_lengthscale: -2.687\n",
      "Iter 57/200 - Loss: 0.875   log_lengthscale: -2.689\n",
      "Iter 58/200 - Loss: 0.900   log_lengthscale: -2.693\n",
      "Iter 59/200 - Loss: 0.860   log_lengthscale: -2.698\n",
      "Iter 60/200 - Loss: 0.928   log_lengthscale: -2.703\n",
      "Iter 61/200 - Loss: 1.066   log_lengthscale: -2.710\n",
      "Iter 62/200 - Loss: 0.923   log_lengthscale: -2.715\n",
      "Iter 63/200 - Loss: 0.966   log_lengthscale: -2.719\n",
      "Iter 64/200 - Loss: 1.042   log_lengthscale: -2.725\n",
      "Iter 65/200 - Loss: 0.768   log_lengthscale: -2.730\n",
      "Iter 66/200 - Loss: 0.959   log_lengthscale: -2.733\n",
      "Iter 67/200 - Loss: 0.939   log_lengthscale: -2.738\n",
      "Iter 68/200 - Loss: 0.805   log_lengthscale: -2.743\n",
      "Iter 69/200 - Loss: 0.892   log_lengthscale: -2.748\n",
      "Iter 70/200 - Loss: 0.966   log_lengthscale: -2.754\n",
      "Iter 71/200 - Loss: 0.771   log_lengthscale: -2.761\n",
      "Iter 72/200 - Loss: 0.869   log_lengthscale: -2.771\n",
      "Iter 73/200 - Loss: 0.858   log_lengthscale: -2.779\n",
      "Iter 74/200 - Loss: 0.836   log_lengthscale: -2.787\n",
      "Iter 75/200 - Loss: 0.726   log_lengthscale: -2.793\n",
      "Iter 76/200 - Loss: 0.880   log_lengthscale: -2.800\n",
      "Iter 77/200 - Loss: 0.782   log_lengthscale: -2.807\n",
      "Iter 78/200 - Loss: 0.853   log_lengthscale: -2.815\n",
      "Iter 79/200 - Loss: 0.819   log_lengthscale: -2.822\n",
      "Iter 80/200 - Loss: 0.916   log_lengthscale: -2.830\n",
      "Iter 81/200 - Loss: 0.793   log_lengthscale: -2.838\n",
      "Iter 82/200 - Loss: 0.955   log_lengthscale: -2.843\n",
      "Iter 83/200 - Loss: 0.736   log_lengthscale: -2.847\n",
      "Iter 84/200 - Loss: 0.755   log_lengthscale: -2.853\n",
      "Iter 85/200 - Loss: 0.705   log_lengthscale: -2.859\n",
      "Iter 86/200 - Loss: 0.696   log_lengthscale: -2.865\n",
      "Iter 87/200 - Loss: 0.680   log_lengthscale: -2.869\n",
      "Iter 88/200 - Loss: 0.697   log_lengthscale: -2.873\n",
      "Iter 89/200 - Loss: 0.701   log_lengthscale: -2.878\n",
      "Iter 90/200 - Loss: 0.663   log_lengthscale: -2.882\n",
      "Iter 91/200 - Loss: 0.684   log_lengthscale: -2.886\n",
      "Iter 92/200 - Loss: 0.727   log_lengthscale: -2.890\n",
      "Iter 93/200 - Loss: 0.671   log_lengthscale: -2.895\n",
      "Iter 94/200 - Loss: 0.866   log_lengthscale: -2.899\n",
      "Iter 95/200 - Loss: 0.670   log_lengthscale: -2.903\n",
      "Iter 96/200 - Loss: 0.739   log_lengthscale: -2.906\n",
      "Iter 97/200 - Loss: 0.687   log_lengthscale: -2.909\n",
      "Iter 98/200 - Loss: 0.632   log_lengthscale: -2.912\n",
      "Iter 99/200 - Loss: 0.645   log_lengthscale: -2.916\n",
      "Iter 100/200 - Loss: 0.637   log_lengthscale: -2.919\n",
      "Iter 101/200 - Loss: 0.686   log_lengthscale: -2.922\n",
      "Iter 102/200 - Loss: 0.670   log_lengthscale: -2.925\n",
      "Iter 103/200 - Loss: 0.708   log_lengthscale: -2.928\n",
      "Iter 104/200 - Loss: 0.602   log_lengthscale: -2.932\n",
      "Iter 105/200 - Loss: 0.808   log_lengthscale: -2.936\n",
      "Iter 106/200 - Loss: 0.673   log_lengthscale: -2.941\n",
      "Iter 107/200 - Loss: 0.633   log_lengthscale: -2.946\n",
      "Iter 108/200 - Loss: 0.618   log_lengthscale: -2.950\n",
      "Iter 109/200 - Loss: 0.656   log_lengthscale: -2.954\n",
      "Iter 110/200 - Loss: 0.676   log_lengthscale: -2.958\n",
      "Iter 111/200 - Loss: 0.649   log_lengthscale: -2.963\n",
      "Iter 112/200 - Loss: 0.580   log_lengthscale: -2.966\n",
      "Iter 113/200 - Loss: 0.603   log_lengthscale: -2.969\n",
      "Iter 114/200 - Loss: 0.621   log_lengthscale: -2.973\n",
      "Iter 115/200 - Loss: 0.594   log_lengthscale: -2.978\n",
      "Iter 116/200 - Loss: 0.542   log_lengthscale: -2.983\n",
      "Iter 117/200 - Loss: 0.549   log_lengthscale: -2.988\n",
      "Iter 118/200 - Loss: 0.549   log_lengthscale: -2.992\n",
      "Iter 119/200 - Loss: 0.647   log_lengthscale: -2.995\n",
      "Iter 120/200 - Loss: 0.598   log_lengthscale: -2.999\n",
      "Iter 121/200 - Loss: 0.564   log_lengthscale: -3.002\n",
      "Iter 122/200 - Loss: 0.585   log_lengthscale: -3.005\n",
      "Iter 123/200 - Loss: 0.586   log_lengthscale: -3.007\n",
      "Iter 124/200 - Loss: 0.605   log_lengthscale: -3.010\n",
      "Iter 125/200 - Loss: 0.660   log_lengthscale: -3.012\n",
      "Iter 126/200 - Loss: 0.496   log_lengthscale: -3.014\n",
      "Iter 127/200 - Loss: 0.599   log_lengthscale: -3.015\n",
      "Iter 128/200 - Loss: 0.546   log_lengthscale: -3.017\n",
      "Iter 129/200 - Loss: 0.527   log_lengthscale: -3.018\n",
      "Iter 130/200 - Loss: 0.597   log_lengthscale: -3.019\n",
      "Iter 131/200 - Loss: 0.522   log_lengthscale: -3.020\n",
      "Iter 132/200 - Loss: 0.543   log_lengthscale: -3.020\n",
      "Iter 133/200 - Loss: 0.524   log_lengthscale: -3.020\n",
      "Iter 134/200 - Loss: 0.596   log_lengthscale: -3.020\n",
      "Iter 135/200 - Loss: 0.544   log_lengthscale: -3.021\n",
      "Iter 136/200 - Loss: 0.541   log_lengthscale: -3.022\n",
      "Iter 137/200 - Loss: 0.580   log_lengthscale: -3.022\n",
      "Iter 138/200 - Loss: 0.544   log_lengthscale: -3.022\n",
      "Iter 139/200 - Loss: 0.560   log_lengthscale: -3.022\n",
      "Iter 140/200 - Loss: 0.563   log_lengthscale: -3.022\n",
      "Iter 141/200 - Loss: 0.567   log_lengthscale: -3.022\n",
      "Iter 142/200 - Loss: 0.576   log_lengthscale: -3.022\n",
      "Iter 143/200 - Loss: 0.539   log_lengthscale: -3.022\n",
      "Iter 144/200 - Loss: 0.536   log_lengthscale: -3.021\n",
      "Iter 145/200 - Loss: 0.513   log_lengthscale: -3.019\n",
      "Iter 146/200 - Loss: 0.502   log_lengthscale: -3.017\n",
      "Iter 147/200 - Loss: 0.537   log_lengthscale: -3.017\n",
      "Iter 148/200 - Loss: 0.481   log_lengthscale: -3.016\n",
      "Iter 149/200 - Loss: 0.520   log_lengthscale: -3.016\n",
      "Iter 150/200 - Loss: 0.527   log_lengthscale: -3.016\n",
      "Iter 151/200 - Loss: 0.537   log_lengthscale: -3.016\n",
      "Iter 152/200 - Loss: 0.501   log_lengthscale: -3.016\n",
      "Iter 153/200 - Loss: 0.548   log_lengthscale: -3.017\n",
      "Iter 154/200 - Loss: 0.526   log_lengthscale: -3.017\n",
      "Iter 155/200 - Loss: 0.545   log_lengthscale: -3.018\n",
      "Iter 156/200 - Loss: 0.482   log_lengthscale: -3.019\n",
      "Iter 157/200 - Loss: 0.474   log_lengthscale: -3.020\n",
      "Iter 158/200 - Loss: 0.522   log_lengthscale: -3.021\n",
      "Iter 159/200 - Loss: 0.474   log_lengthscale: -3.022\n",
      "Iter 160/200 - Loss: 0.488   log_lengthscale: -3.023\n",
      "Iter 161/200 - Loss: 0.489   log_lengthscale: -3.024\n",
      "Iter 162/200 - Loss: 0.492   log_lengthscale: -3.025\n",
      "Iter 163/200 - Loss: 0.490   log_lengthscale: -3.027\n",
      "Iter 164/200 - Loss: 0.467   log_lengthscale: -3.028\n",
      "Iter 165/200 - Loss: 0.484   log_lengthscale: -3.030\n",
      "Iter 166/200 - Loss: 0.523   log_lengthscale: -3.032\n",
      "Iter 167/200 - Loss: 0.476   log_lengthscale: -3.034\n",
      "Iter 168/200 - Loss: 0.496   log_lengthscale: -3.036\n",
      "Iter 169/200 - Loss: 0.494   log_lengthscale: -3.038\n",
      "Iter 170/200 - Loss: 0.475   log_lengthscale: -3.039\n",
      "Iter 171/200 - Loss: 0.490   log_lengthscale: -3.042\n",
      "Iter 172/200 - Loss: 0.521   log_lengthscale: -3.045\n",
      "Iter 173/200 - Loss: 0.489   log_lengthscale: -3.047\n",
      "Iter 174/200 - Loss: 0.464   log_lengthscale: -3.050\n",
      "Iter 175/200 - Loss: 0.457   log_lengthscale: -3.052\n",
      "Iter 176/200 - Loss: 0.451   log_lengthscale: -3.055\n",
      "Iter 177/200 - Loss: 0.447   log_lengthscale: -3.058\n",
      "Iter 178/200 - Loss: 0.475   log_lengthscale: -3.060\n",
      "Iter 179/200 - Loss: 0.494   log_lengthscale: -3.062\n",
      "Iter 180/200 - Loss: 0.445   log_lengthscale: -3.064\n",
      "Iter 181/200 - Loss: 0.471   log_lengthscale: -3.066\n",
      "Iter 182/200 - Loss: 0.450   log_lengthscale: -3.069\n",
      "Iter 183/200 - Loss: 0.418   log_lengthscale: -3.071\n",
      "Iter 184/200 - Loss: 0.446   log_lengthscale: -3.073\n",
      "Iter 185/200 - Loss: 0.473   log_lengthscale: -3.075\n",
      "Iter 186/200 - Loss: 0.445   log_lengthscale: -3.076\n",
      "Iter 187/200 - Loss: 0.500   log_lengthscale: -3.077\n",
      "Iter 188/200 - Loss: 0.500   log_lengthscale: -3.078\n",
      "Iter 189/200 - Loss: 0.473   log_lengthscale: -3.078\n",
      "Iter 190/200 - Loss: 0.418   log_lengthscale: -3.079\n",
      "Iter 191/200 - Loss: 0.488   log_lengthscale: -3.080\n",
      "Iter 192/200 - Loss: 0.420   log_lengthscale: -3.081\n",
      "Iter 193/200 - Loss: 0.453   log_lengthscale: -3.081\n",
      "Iter 194/200 - Loss: 0.415   log_lengthscale: -3.082\n",
      "Iter 195/200 - Loss: 0.452   log_lengthscale: -3.082\n",
      "Iter 196/200 - Loss: 0.429   log_lengthscale: -3.083\n",
      "Iter 197/200 - Loss: 0.427   log_lengthscale: -3.083\n",
      "Iter 198/200 - Loss: 0.449   log_lengthscale: -3.084\n",
      "Iter 199/200 - Loss: 0.478   log_lengthscale: -3.084\n",
      "Iter 200/200 - Loss: 0.455   log_lengthscale: -3.085\n",
      "CPU times: user 5.33 s, sys: 80 ms, total: 5.41 s\n",
      "Wall time: 5.4 s\n"
     ]
    }
   ],
   "source": [
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "def train():\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "    optimizer.n_iter = 0\n",
    "    for i in range(200):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_x)\n",
    "        loss = -model.marginal_log_likelihood(likelihood, output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.n_iter += 1\n",
    "        print('Iter %d/200 - Loss: %.3f   log_lengthscale: %.3f' % (\n",
    "            i + 1, loss.data[0],\n",
    "            model.covar_module.base_kernel_module.log_lengthscale.data.squeeze()[0],\n",
    "        ))\n",
    "        optimizer.step()\n",
    "%time train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAADRCAYAAAAueRwfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa8b40b7810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "f, observed_ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "test_x = Variable(torch.linspace(0, 1, 1001)).cuda()\n",
    "predictions = likelihood(model(test_x))\n",
    "\n",
    "def ax_plot(ax, rand_var, title):\n",
    "    ax.plot(train_x.data.cpu().numpy(), train_y.data.cpu().numpy(), 'k*')\n",
    "    pred_labels = rand_var.mean().ge(0.5).float().mul(2).sub(1)\n",
    "    ax.plot(test_x.data.cpu().numpy(), pred_labels.data.cpu().numpy(), 'b')\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "    ax.set_title(title)\n",
    "\n",
    "ax_plot(observed_ax, predictions, 'Observed Values (Likelihood)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
