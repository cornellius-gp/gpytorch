{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"hatch.linewidth\" on line 54 in\n",
      "/home/gpleiss/.dotfiles/matplotlibrc.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "n = 30\n",
    "train_x = torch.zeros(int(pow(n, 2)), 2)\n",
    "train_y = torch.zeros(int(pow(n, 2)))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        train_x[i * n + j][0] = float(i) / (n - 1)\n",
    "        train_x[i * n + j][1] = float(j) / (n - 1)\n",
    "        train_y[i * n + j] = pow(-1, int(3 * i / n + int(3 * j / n)))\n",
    "train_x = Variable(train_x)\n",
    "train_y = Variable(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from gpytorch.kernels import RBFKernel, GridInterpolationKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood, BernoulliLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GPClassificationModel(gpytorch.models.GridInducingVariationalGP):\n",
    "    def __init__(self):\n",
    "        super(GPClassificationModel, self).__init__(grid_size=10, grid_bounds=[(0, 1), (0, 1)])\n",
    "        self.mean_module = ConstantMean(constant_bounds=[-1e-5, 1e-5])\n",
    "        self.covar_module = RBFKernel(log_lengthscale_bounds=(-5, 6))\n",
    "        self.register_parameter('log_outputscale', nn.Parameter(torch.Tensor([0])), bounds=(-5,6))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        covar_x = covar_x.mul(self.log_outputscale.exp())\n",
    "        latent_pred = GaussianRandomVariable(mean_x, covar_x)\n",
    "        return latent_pred\n",
    "    \n",
    "model = GPClassificationModel()\n",
    "likelihood = BernoulliLikelihood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_model_and_predictions(model, plot_train_data=True):\n",
    "\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: 270.905   log_lengthscale: 0.000\n",
      "Iter 2/200 - Loss: 31.487   log_lengthscale: -0.200\n",
      "Iter 3/200 - Loss: 7.817   log_lengthscale: -0.396\n",
      "Iter 4/200 - Loss: 8.438   log_lengthscale: -0.567\n",
      "Iter 5/200 - Loss: 11.023   log_lengthscale: -0.726\n",
      "Iter 6/200 - Loss: 8.230   log_lengthscale: -0.881\n",
      "Iter 7/200 - Loss: 7.089   log_lengthscale: -1.028\n",
      "Iter 8/200 - Loss: 5.649   log_lengthscale: -1.166\n",
      "Iter 9/200 - Loss: 4.708   log_lengthscale: -1.296\n",
      "Iter 10/200 - Loss: 4.842   log_lengthscale: -1.417\n",
      "Iter 11/200 - Loss: 4.833   log_lengthscale: -1.528\n",
      "Iter 12/200 - Loss: 4.221   log_lengthscale: -1.631\n",
      "Iter 13/200 - Loss: 3.868   log_lengthscale: -1.727\n",
      "Iter 14/200 - Loss: 3.910   log_lengthscale: -1.816\n",
      "Iter 15/200 - Loss: 3.567   log_lengthscale: -1.897\n",
      "Iter 16/200 - Loss: 2.815   log_lengthscale: -1.972\n",
      "Iter 17/200 - Loss: 3.380   log_lengthscale: -2.041\n",
      "Iter 18/200 - Loss: 3.475   log_lengthscale: -2.104\n",
      "Iter 19/200 - Loss: 2.824   log_lengthscale: -2.162\n",
      "Iter 20/200 - Loss: 2.533   log_lengthscale: -2.215\n",
      "Iter 21/200 - Loss: 2.995   log_lengthscale: -2.265\n",
      "Iter 22/200 - Loss: 2.531   log_lengthscale: -2.310\n",
      "Iter 23/200 - Loss: 2.178   log_lengthscale: -2.353\n",
      "Iter 24/200 - Loss: 2.732   log_lengthscale: -2.391\n",
      "Iter 25/200 - Loss: 2.169   log_lengthscale: -2.427\n",
      "Iter 26/200 - Loss: 2.239   log_lengthscale: -2.460\n",
      "Iter 27/200 - Loss: 2.394   log_lengthscale: -2.491\n",
      "Iter 28/200 - Loss: 2.359   log_lengthscale: -2.519\n",
      "Iter 29/200 - Loss: 1.916   log_lengthscale: -2.545\n",
      "Iter 30/200 - Loss: 2.040   log_lengthscale: -2.570\n",
      "Iter 31/200 - Loss: 1.846   log_lengthscale: -2.592\n",
      "Iter 32/200 - Loss: 1.705   log_lengthscale: -2.613\n",
      "Iter 33/200 - Loss: 1.713   log_lengthscale: -2.632\n",
      "Iter 34/200 - Loss: 1.762   log_lengthscale: -2.650\n",
      "Iter 35/200 - Loss: 1.764   log_lengthscale: -2.666\n",
      "Iter 36/200 - Loss: 1.504   log_lengthscale: -2.681\n",
      "Iter 37/200 - Loss: 1.586   log_lengthscale: -2.695\n",
      "Iter 38/200 - Loss: 1.542   log_lengthscale: -2.709\n",
      "Iter 39/200 - Loss: 1.386   log_lengthscale: -2.721\n",
      "Iter 40/200 - Loss: 1.420   log_lengthscale: -2.732\n",
      "Iter 41/200 - Loss: 1.488   log_lengthscale: -2.742\n",
      "Iter 42/200 - Loss: 1.356   log_lengthscale: -2.752\n",
      "Iter 43/200 - Loss: 1.138   log_lengthscale: -2.761\n",
      "Iter 44/200 - Loss: 0.948   log_lengthscale: -2.770\n",
      "Iter 45/200 - Loss: 1.124   log_lengthscale: -2.778\n",
      "Iter 46/200 - Loss: 1.352   log_lengthscale: -2.785\n",
      "Iter 47/200 - Loss: 0.874   log_lengthscale: -2.792\n",
      "Iter 48/200 - Loss: 0.981   log_lengthscale: -2.798\n",
      "Iter 49/200 - Loss: 0.992   log_lengthscale: -2.804\n",
      "Iter 50/200 - Loss: 0.931   log_lengthscale: -2.810\n",
      "Iter 51/200 - Loss: 0.929   log_lengthscale: -2.815\n",
      "Iter 52/200 - Loss: 1.072   log_lengthscale: -2.820\n",
      "Iter 53/200 - Loss: 0.856   log_lengthscale: -2.825\n",
      "Iter 54/200 - Loss: 0.709   log_lengthscale: -2.829\n",
      "Iter 55/200 - Loss: 0.947   log_lengthscale: -2.833\n",
      "Iter 56/200 - Loss: 0.728   log_lengthscale: -2.837\n",
      "Iter 57/200 - Loss: 0.839   log_lengthscale: -2.840\n",
      "Iter 58/200 - Loss: 0.809   log_lengthscale: -2.843\n",
      "Iter 59/200 - Loss: 0.691   log_lengthscale: -2.846\n",
      "Iter 60/200 - Loss: 0.830   log_lengthscale: -2.849\n",
      "Iter 61/200 - Loss: 0.612   log_lengthscale: -2.852\n",
      "Iter 62/200 - Loss: 0.693   log_lengthscale: -2.855\n",
      "Iter 63/200 - Loss: 0.640   log_lengthscale: -2.857\n",
      "Iter 64/200 - Loss: 0.626   log_lengthscale: -2.860\n",
      "Iter 65/200 - Loss: 0.652   log_lengthscale: -2.862\n",
      "Iter 66/200 - Loss: 0.589   log_lengthscale: -2.864\n",
      "Iter 67/200 - Loss: 0.615   log_lengthscale: -2.866\n",
      "Iter 68/200 - Loss: 0.535   log_lengthscale: -2.868\n",
      "Iter 69/200 - Loss: 0.580   log_lengthscale: -2.870\n",
      "Iter 70/200 - Loss: 0.609   log_lengthscale: -2.872\n",
      "Iter 71/200 - Loss: 0.547   log_lengthscale: -2.874\n",
      "Iter 72/200 - Loss: 0.538   log_lengthscale: -2.875\n",
      "Iter 73/200 - Loss: 0.507   log_lengthscale: -2.877\n",
      "Iter 74/200 - Loss: 0.546   log_lengthscale: -2.878\n",
      "Iter 75/200 - Loss: 0.536   log_lengthscale: -2.880\n",
      "Iter 76/200 - Loss: 0.569   log_lengthscale: -2.881\n",
      "Iter 77/200 - Loss: 0.518   log_lengthscale: -2.882\n",
      "Iter 78/200 - Loss: 0.507   log_lengthscale: -2.883\n",
      "Iter 79/200 - Loss: 0.534   log_lengthscale: -2.884\n",
      "Iter 80/200 - Loss: 0.478   log_lengthscale: -2.886\n",
      "Iter 81/200 - Loss: 0.517   log_lengthscale: -2.887\n",
      "Iter 82/200 - Loss: 0.486   log_lengthscale: -2.888\n",
      "Iter 83/200 - Loss: 0.473   log_lengthscale: -2.888\n",
      "Iter 84/200 - Loss: 0.442   log_lengthscale: -2.889\n",
      "Iter 85/200 - Loss: 0.442   log_lengthscale: -2.890\n",
      "Iter 86/200 - Loss: 0.426   log_lengthscale: -2.891\n",
      "Iter 87/200 - Loss: 0.427   log_lengthscale: -2.892\n",
      "Iter 88/200 - Loss: 0.476   log_lengthscale: -2.892\n",
      "Iter 89/200 - Loss: 0.429   log_lengthscale: -2.893\n",
      "Iter 90/200 - Loss: 0.409   log_lengthscale: -2.894\n",
      "Iter 91/200 - Loss: 0.437   log_lengthscale: -2.894\n",
      "Iter 92/200 - Loss: 0.392   log_lengthscale: -2.895\n",
      "Iter 93/200 - Loss: 0.422   log_lengthscale: -2.895\n",
      "Iter 94/200 - Loss: 0.417   log_lengthscale: -2.896\n",
      "Iter 95/200 - Loss: 0.414   log_lengthscale: -2.896\n",
      "Iter 96/200 - Loss: 0.396   log_lengthscale: -2.897\n",
      "Iter 97/200 - Loss: 0.389   log_lengthscale: -2.897\n",
      "Iter 98/200 - Loss: 0.444   log_lengthscale: -2.897\n",
      "Iter 99/200 - Loss: 0.420   log_lengthscale: -2.898\n",
      "Iter 100/200 - Loss: 0.423   log_lengthscale: -2.898\n",
      "Iter 101/200 - Loss: 0.400   log_lengthscale: -2.898\n",
      "Iter 102/200 - Loss: 0.363   log_lengthscale: -2.899\n",
      "Iter 103/200 - Loss: 0.374   log_lengthscale: -2.899\n",
      "Iter 104/200 - Loss: 0.396   log_lengthscale: -2.899\n",
      "Iter 105/200 - Loss: 0.421   log_lengthscale: -2.899\n",
      "Iter 106/200 - Loss: 0.374   log_lengthscale: -2.900\n",
      "Iter 107/200 - Loss: 0.366   log_lengthscale: -2.900\n",
      "Iter 108/200 - Loss: 0.408   log_lengthscale: -2.900\n",
      "Iter 109/200 - Loss: 0.380   log_lengthscale: -2.900\n",
      "Iter 110/200 - Loss: 0.343   log_lengthscale: -2.900\n",
      "Iter 111/200 - Loss: 0.352   log_lengthscale: -2.901\n",
      "Iter 112/200 - Loss: 0.362   log_lengthscale: -2.901\n",
      "Iter 113/200 - Loss: 0.377   log_lengthscale: -2.901\n",
      "Iter 114/200 - Loss: 0.384   log_lengthscale: -2.901\n",
      "Iter 115/200 - Loss: 0.382   log_lengthscale: -2.901\n",
      "Iter 116/200 - Loss: 0.364   log_lengthscale: -2.902\n",
      "Iter 117/200 - Loss: 0.332   log_lengthscale: -2.902\n",
      "Iter 118/200 - Loss: 0.346   log_lengthscale: -2.902\n",
      "Iter 119/200 - Loss: 0.325   log_lengthscale: -2.902\n",
      "Iter 120/200 - Loss: 0.346   log_lengthscale: -2.902\n",
      "Iter 121/200 - Loss: 0.363   log_lengthscale: -2.902\n",
      "Iter 122/200 - Loss: 0.354   log_lengthscale: -2.902\n",
      "Iter 123/200 - Loss: 0.338   log_lengthscale: -2.903\n",
      "Iter 124/200 - Loss: 0.355   log_lengthscale: -2.903\n",
      "Iter 125/200 - Loss: 0.369   log_lengthscale: -2.903\n",
      "Iter 126/200 - Loss: 0.318   log_lengthscale: -2.903\n",
      "Iter 127/200 - Loss: 0.331   log_lengthscale: -2.903\n",
      "Iter 128/200 - Loss: 0.333   log_lengthscale: -2.903\n",
      "Iter 129/200 - Loss: 0.335   log_lengthscale: -2.903\n",
      "Iter 130/200 - Loss: 0.333   log_lengthscale: -2.904\n",
      "Iter 131/200 - Loss: 0.334   log_lengthscale: -2.904\n",
      "Iter 132/200 - Loss: 0.333   log_lengthscale: -2.904\n",
      "Iter 133/200 - Loss: 0.332   log_lengthscale: -2.904\n",
      "Iter 134/200 - Loss: 0.325   log_lengthscale: -2.904\n",
      "Iter 135/200 - Loss: 0.315   log_lengthscale: -2.904\n",
      "Iter 136/200 - Loss: 0.348   log_lengthscale: -2.904\n",
      "Iter 137/200 - Loss: 0.324   log_lengthscale: -2.904\n",
      "Iter 138/200 - Loss: 0.331   log_lengthscale: -2.904\n",
      "Iter 139/200 - Loss: 0.302   log_lengthscale: -2.905\n",
      "Iter 140/200 - Loss: 0.354   log_lengthscale: -2.905\n",
      "Iter 141/200 - Loss: 0.332   log_lengthscale: -2.905\n",
      "Iter 142/200 - Loss: 0.312   log_lengthscale: -2.905\n",
      "Iter 143/200 - Loss: 0.313   log_lengthscale: -2.905\n",
      "Iter 144/200 - Loss: 0.333   log_lengthscale: -2.905\n",
      "Iter 145/200 - Loss: 0.277   log_lengthscale: -2.905\n",
      "Iter 146/200 - Loss: 0.326   log_lengthscale: -2.906\n",
      "Iter 147/200 - Loss: 0.342   log_lengthscale: -2.906\n",
      "Iter 148/200 - Loss: 0.325   log_lengthscale: -2.906\n",
      "Iter 149/200 - Loss: 0.331   log_lengthscale: -2.906\n",
      "Iter 150/200 - Loss: 0.329   log_lengthscale: -2.906\n",
      "Iter 151/200 - Loss: 0.319   log_lengthscale: -2.906\n",
      "Iter 152/200 - Loss: 0.301   log_lengthscale: -2.906\n",
      "Iter 153/200 - Loss: 0.309   log_lengthscale: -2.906\n",
      "Iter 154/200 - Loss: 0.336   log_lengthscale: -2.906\n",
      "Iter 155/200 - Loss: 0.287   log_lengthscale: -2.906\n",
      "Iter 156/200 - Loss: 0.294   log_lengthscale: -2.906\n",
      "Iter 157/200 - Loss: 0.297   log_lengthscale: -2.907\n",
      "Iter 158/200 - Loss: 0.297   log_lengthscale: -2.907\n",
      "Iter 159/200 - Loss: 0.299   log_lengthscale: -2.907\n",
      "Iter 160/200 - Loss: 0.309   log_lengthscale: -2.907\n",
      "Iter 161/200 - Loss: 0.300   log_lengthscale: -2.907\n",
      "Iter 162/200 - Loss: 0.301   log_lengthscale: -2.907\n",
      "Iter 163/200 - Loss: 0.298   log_lengthscale: -2.907\n",
      "Iter 164/200 - Loss: 0.286   log_lengthscale: -2.907\n",
      "Iter 165/200 - Loss: 0.279   log_lengthscale: -2.907\n",
      "Iter 166/200 - Loss: 0.295   log_lengthscale: -2.907\n",
      "Iter 167/200 - Loss: 0.307   log_lengthscale: -2.908\n",
      "Iter 168/200 - Loss: 0.313   log_lengthscale: -2.908\n",
      "Iter 169/200 - Loss: 0.278   log_lengthscale: -2.908\n",
      "Iter 170/200 - Loss: 0.290   log_lengthscale: -2.908\n",
      "Iter 171/200 - Loss: 0.304   log_lengthscale: -2.908\n",
      "Iter 172/200 - Loss: 0.294   log_lengthscale: -2.908\n",
      "Iter 173/200 - Loss: 0.285   log_lengthscale: -2.908\n",
      "Iter 174/200 - Loss: 0.269   log_lengthscale: -2.908\n",
      "Iter 175/200 - Loss: 0.272   log_lengthscale: -2.908\n",
      "Iter 176/200 - Loss: 0.293   log_lengthscale: -2.908\n",
      "Iter 177/200 - Loss: 0.281   log_lengthscale: -2.908\n",
      "Iter 178/200 - Loss: 0.289   log_lengthscale: -2.908\n",
      "Iter 179/200 - Loss: 0.295   log_lengthscale: -2.908\n",
      "Iter 180/200 - Loss: 0.288   log_lengthscale: -2.908\n",
      "Iter 181/200 - Loss: 0.273   log_lengthscale: -2.909\n",
      "Iter 182/200 - Loss: 0.269   log_lengthscale: -2.909\n",
      "Iter 183/200 - Loss: 0.290   log_lengthscale: -2.909\n",
      "Iter 184/200 - Loss: 0.293   log_lengthscale: -2.909\n",
      "Iter 185/200 - Loss: 0.277   log_lengthscale: -2.909\n",
      "Iter 186/200 - Loss: 0.280   log_lengthscale: -2.909\n",
      "Iter 187/200 - Loss: 0.277   log_lengthscale: -2.909\n",
      "Iter 188/200 - Loss: 0.274   log_lengthscale: -2.909\n",
      "Iter 189/200 - Loss: 0.292   log_lengthscale: -2.909\n",
      "Iter 190/200 - Loss: 0.261   log_lengthscale: -2.909\n",
      "Iter 191/200 - Loss: 0.276   log_lengthscale: -2.909\n",
      "Iter 192/200 - Loss: 0.264   log_lengthscale: -2.909\n",
      "Iter 193/200 - Loss: 0.283   log_lengthscale: -2.909\n",
      "Iter 194/200 - Loss: 0.275   log_lengthscale: -2.909\n",
      "Iter 195/200 - Loss: 0.284   log_lengthscale: -2.909\n",
      "Iter 196/200 - Loss: 0.280   log_lengthscale: -2.910\n",
      "Iter 197/200 - Loss: 0.268   log_lengthscale: -2.910\n",
      "Iter 198/200 - Loss: 0.286   log_lengthscale: -2.910\n",
      "Iter 199/200 - Loss: 0.282   log_lengthscale: -2.910\n",
      "Iter 200/200 - Loss: 0.276   log_lengthscale: -2.910\n",
      "CPU times: user 17.2 s, sys: 100 ms, total: 17.3 s\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.2)\n",
    "optimizer.n_iter = 0\n",
    "\n",
    "def train():\n",
    "    for i in range(200):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_x)\n",
    "        loss = -model.marginal_log_likelihood(likelihood, output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.n_iter += 1\n",
    "        print('Iter %d/200 - Loss: %.3f   log_lengthscale: %.3f' % (\n",
    "            i + 1, loss.data[0],\n",
    "            model.covar_module.base_kernel_module.log_lengthscale.data.squeeze()[0],\n",
    "        ))\n",
    "        optimizer.step()\n",
    "%time train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAADRCAYAAAA9rlzrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcdf4924350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "f, observed_ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "n = 100\n",
    "test_x = Variable(torch.zeros(int(pow(n, 2)), 2))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        test_x.data[i * n + j][0] = float(i) / (n-1)\n",
    "        test_x.data[i * n + j][1] = float(j) / (n-1)\n",
    "predictions = likelihood(model(test_x))\n",
    "\n",
    "def ax_plot(ax, rand_var, title):\n",
    "    pred_labels = rand_var.mean().ge(0.5).float().mul(2).sub(1).data.numpy()\n",
    "    color = []\n",
    "    for i in range(len(pred_labels)):\n",
    "        if pred_labels[i] == 1:\n",
    "            color.append('y')\n",
    "        else:\n",
    "            color.append('r')\n",
    "    ax.scatter(test_x.data[:, 0].numpy(), test_x.data[:, 1].numpy(), color=color, s=1)\n",
    "    ax.set_ylim([-0.5, 1.5])\n",
    "    ax.set_title(title)\n",
    "\n",
    "ax_plot(observed_ax, predictions, 'Predicted Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
