{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative representation of MultitaskMultivariateNormal\n",
    "\n",
    "## Issue:\n",
    "Currently, the interleaved/non-interleaved representation of MTMVN creates a bunch of headaches. It would be nice to have a higher-level API that abstracts away from these details. \n",
    "\n",
    "\n",
    "## Suggestion:\n",
    "Represent the covariance matrix as an \"unrolled\" tensor (e.g. `n x n x m x m`), instead of a `nm x nm` covariance matrix. That way things like scalarizations are easily done, and reshaping/viewing/getting items can be done more straightforwardly. \n",
    "\n",
    "\n",
    "## Challenge:\n",
    "In order to sample from this MVN, we need to compute the full `nm x nm` covariance matrix (to either compute the cholesky decomposition or apply iterative approximate root decomposition methods. We need to make sure this is transparent, fast, and happens without much overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 3  # number of points\n",
    "m = 2  # number of outputs\n",
    "\n",
    "# create some full covar\n",
    "\n",
    "def make_rand_covar(k, batch_shape=torch.Size()):\n",
    "    a = torch.rand(*batch_shape, k, k)\n",
    "    return a @ a.transpose(-1, -2) + torch.diag_embed(torch.rand(k))\n",
    "    \n",
    "A = make_rand_covar(n * m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### interleaved: block matrix where each block is an intra-point, cross-task covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_inter = torch.zeros(n, n, m, m)\n",
    "\n",
    "# this is obviously super inefficient, but it makes clear what we want\n",
    "for i in range(n):\n",
    "    for i_ in range(n):\n",
    "        for j in range(m):\n",
    "            for j_ in range(m):\n",
    "                C_inter[i, i_, j, j_] = A[i*m+j, i_*m+j_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6730, 1.4068, 1.4398, 1.0731, 1.8534, 0.9899],\n",
       "        [1.4068, 3.3130, 2.0636, 1.8746, 3.3943, 2.4631],\n",
       "        [1.4398, 2.0636, 2.5348, 1.4629, 2.6626, 1.8031],\n",
       "        [1.0731, 1.8746, 1.4629, 2.2579, 2.3630, 1.6523],\n",
       "        [1.8534, 3.3943, 2.6626, 2.3630, 4.4928, 3.0654],\n",
       "        [0.9899, 2.4631, 1.8031, 1.6523, 3.0654, 3.7077]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6730, 1.4068, 1.4398, 1.0731, 1.8534, 0.9899],\n",
       "        [1.4068, 3.3130, 2.0636, 1.8746, 3.3943, 2.4631],\n",
       "        [1.4398, 2.0636, 2.5348, 1.4629, 2.6626, 1.8031],\n",
       "        [1.0731, 1.8746, 1.4629, 2.2579, 2.3630, 1.6523],\n",
       "        [1.8534, 3.3943, 2.6626, 2.3630, 4.4928, 3.0654],\n",
       "        [0.9899, 2.4631, 1.8031, 1.6523, 3.0654, 3.7077]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can construct the full matrix as follows:\n",
    "C_inter.permute(0, 2, 1, 3).reshape(m*n, m*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.6730, 1.4068, 1.4398, 1.0731, 1.8534, 0.9899],\n",
       "         [1.4068, 3.3130, 2.0636, 1.8746, 3.3943, 2.4631],\n",
       "         [1.4398, 2.0636, 2.5348, 1.4629, 2.6626, 1.8031],\n",
       "         [1.0731, 1.8746, 1.4629, 2.2579, 2.3630, 1.6523],\n",
       "         [1.8534, 3.3943, 2.6626, 2.3630, 4.4928, 3.0654],\n",
       "         [0.9899, 2.4631, 1.8031, 1.6523, 3.0654, 3.7077]],\n",
       "\n",
       "        [[2.6730, 2.4068, 2.4398, 2.0731, 2.8534, 1.9899],\n",
       "         [2.4068, 4.3130, 3.0636, 2.8746, 4.3943, 3.4631],\n",
       "         [2.4398, 3.0636, 3.5348, 2.4629, 3.6626, 2.8031],\n",
       "         [2.0731, 2.8746, 2.4629, 3.2579, 3.3630, 2.6523],\n",
       "         [2.8534, 4.3943, 3.6626, 3.3630, 5.4928, 4.0654],\n",
       "         [1.9899, 3.4631, 2.8031, 2.6523, 4.0654, 4.7077]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batched version\n",
    "b = 2\n",
    "A_b = torch.stack([A, A + 1])\n",
    "C_inter_b = torch.zeros(b, n, n, m, m)\n",
    "\n",
    "# this is obviously super inefficient, but it makes clear what we want\n",
    "for b_ in range(b):\n",
    "    for i in range(n):\n",
    "        for i_ in range(n):\n",
    "            for j in range(m):\n",
    "                for j_ in range(m):\n",
    "                    C_inter_b[b_, i, i_, j, j_] = A_b[b_, i*m+j, i_*m+j_]\n",
    "                    \n",
    "C_inter_b.permute(0, 1, 3, 2, 4).reshape(b, m*n, m*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.6730, 1.4068, 1.4398, 1.0731, 1.8534, 0.9899],\n",
       "         [1.4068, 3.3130, 2.0636, 1.8746, 3.3943, 2.4631],\n",
       "         [1.4398, 2.0636, 2.5348, 1.4629, 2.6626, 1.8031],\n",
       "         [1.0731, 1.8746, 1.4629, 2.2579, 2.3630, 1.6523],\n",
       "         [1.8534, 3.3943, 2.6626, 2.3630, 4.4928, 3.0654],\n",
       "         [0.9899, 2.4631, 1.8031, 1.6523, 3.0654, 3.7077]],\n",
       "\n",
       "        [[2.6730, 2.4068, 2.4398, 2.0731, 2.8534, 1.9899],\n",
       "         [2.4068, 4.3130, 3.0636, 2.8746, 4.3943, 3.4631],\n",
       "         [2.4398, 3.0636, 3.5348, 2.4629, 3.6626, 2.8031],\n",
       "         [2.0731, 2.8746, 2.4629, 3.2579, 3.3630, 2.6523],\n",
       "         [2.8534, 4.3943, 3.6626, 3.3630, 5.4928, 4.0654],\n",
       "         [1.9899, 3.4631, 2.8031, 2.6523, 4.0654, 4.7077]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the general formulation:\n",
    "batch_shape = C_inter_b.shape[:-4]\n",
    "C_inter_b.permute(*range(len(batch_shape)), -4, -2, -3, -1).reshape(*batch_shape, m*n, m*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how do we go back? I.e. construct C_inter efficiently form the full matrix? Just do the same thing in reverse\n",
    "\n",
    "batch_shape = A_b.shape[:-2]\n",
    "C_inter_b_recov = A_b.reshape(*batch_shape, n, m, n, m).permute(*range(len(batch_shape)), -4, -2, -3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(C_inter_b, C_inter_b_recov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### non-interleaved: block matrix where each block is an intra-task, cross-point covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_noninter = torch.zeros(m, m, n, n)\n",
    "\n",
    "# this is obviously super inefficient, but it makes clear what we want\n",
    "for i in range(m):\n",
    "    for i_ in range(m):\n",
    "        for j in range(n):\n",
    "            for j_ in range(n):\n",
    "                C_noninter[i, i_, j, j_] = A[i*n+j, i_*n+j_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6730, 1.4068, 1.4398, 1.0731, 1.8534, 0.9899],\n",
       "        [1.4068, 3.3130, 2.0636, 1.8746, 3.3943, 2.4631],\n",
       "        [1.4398, 2.0636, 2.5348, 1.4629, 2.6626, 1.8031],\n",
       "        [1.0731, 1.8746, 1.4629, 2.2579, 2.3630, 1.6523],\n",
       "        [1.8534, 3.3943, 2.6626, 2.3630, 4.4928, 3.0654],\n",
       "        [0.9899, 2.4631, 1.8031, 1.6523, 3.0654, 3.7077]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6730, 1.4068, 1.4398, 1.0731, 1.8534, 0.9899],\n",
       "        [1.4068, 3.3130, 2.0636, 1.8746, 3.3943, 2.4631],\n",
       "        [1.4398, 2.0636, 2.5348, 1.4629, 2.6626, 1.8031],\n",
       "        [1.0731, 1.8746, 1.4629, 2.2579, 2.3630, 1.6523],\n",
       "        [1.8534, 3.3943, 2.6626, 2.3630, 4.4928, 3.0654],\n",
       "        [0.9899, 2.4631, 1.8031, 1.6523, 3.0654, 3.7077]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# again we can construct the matrix as follows:\n",
    "C_noninter.permute(0, 2, 1, 3).reshape(m*n, m*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batched version\n",
    "C_noninter_b = torch.zeros(b, m, m, n, n)\n",
    "\n",
    "# this is obviously super inefficient, but it makes clear what we want\n",
    "for b_ in range(b):\n",
    "    for i in range(m):\n",
    "        for i_ in range(m):\n",
    "            for j in range(n):\n",
    "                for j_ in range(n):\n",
    "                    C_noninter_b[b_, i, i_, j, j_] = A_b[b_, i*n+j, i_*n+j_]\n",
    "                    \n",
    "torch.allclose(\n",
    "    C_noninter_b.permute(0, 1, 3, 2, 4).reshape(b, m*n, m*n),\n",
    "    A_b,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and again we can go back the same way\n",
    "\n",
    "batch_shape = A_b.shape[:-2]\n",
    "C_noninter_b_recov = A_b.reshape(*batch_shape, m, n, m, n).permute(*range(len(batch_shape)), -4, -2, -3, -1)\n",
    "torch.allclose(C_noninter_b, C_noninter_b_recov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alternate mixed-interleaved: block matrix where each block is an intra-point, cross-task covariance\n",
    "\n",
    "This seems to be the most useful internal representation, as this means we don't have to do any permuting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate representation\n",
    "C_alt = torch.zeros(n, m, n, m)\n",
    "\n",
    "# this is (obciously) super inefficient, but it makes clear what we want\n",
    "for i in range(n):\n",
    "    for j in range(m):\n",
    "        for i_ in range(n):    \n",
    "            for j_ in range(m):\n",
    "                C_alt[i, j, i_, j_] = A[i*m+j, i_*m+j_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6730, 1.4068, 1.4398, 1.0731, 1.8534, 0.9899],\n",
       "        [1.4068, 3.3130, 2.0636, 1.8746, 3.3943, 2.4631],\n",
       "        [1.4398, 2.0636, 2.5348, 1.4629, 2.6626, 1.8031],\n",
       "        [1.0731, 1.8746, 1.4629, 2.2579, 2.3630, 1.6523],\n",
       "        [1.8534, 3.3943, 2.6626, 2.3630, 4.4928, 3.0654],\n",
       "        [0.9899, 2.4631, 1.8031, 1.6523, 3.0654, 3.7077]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6730, 1.4068, 1.4398, 1.0731, 1.8534, 0.9899],\n",
       "        [1.4068, 3.3130, 2.0636, 1.8746, 3.3943, 2.4631],\n",
       "        [1.4398, 2.0636, 2.5348, 1.4629, 2.6626, 1.8031],\n",
       "        [1.0731, 1.8746, 1.4629, 2.2579, 2.3630, 1.6523],\n",
       "        [1.8534, 3.3943, 2.6626, 2.3630, 4.4928, 3.0654],\n",
       "        [0.9899, 2.4631, 1.8031, 1.6523, 3.0654, 3.7077]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is super straightforward\n",
    "C_alt.view(n*m, n*m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternate representation\n",
    "C_alt_b = torch.zeros(b, n, m, n, m)\n",
    "\n",
    "# this is (obciously) super inefficient, but it makes clear what we want\n",
    "for b_ in range(b):\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            for i_ in range(n):    \n",
    "                for j_ in range(m):\n",
    "                    C_alt_b[b_, i, j, i_, j_] = A_b[b_, i*m+j, i_*m+j_]\n",
    "\n",
    "batch_shape = C_alt_b.shape[:-4]\n",
    "torch.allclose(\n",
    "    C_alt_b.view(*batch_shape, n*m, n*m),\n",
    "    A_b,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ....and going back\n",
    "\n",
    "batch_shape = A_b.shape[:-2]\n",
    "C_alt_b_recov = A_b.reshape(*batch_shape, n, m, n, m) #.permute(*range(len(batch_shape)), -4, -2, -3, -1)\n",
    "torch.allclose(C_alt_b, C_alt_b_recov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: What if the tensor memory layout is different? Do we need to handle that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalarizing\n",
    "\n",
    "This representation makes scalarizing across the outputs trivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1402, 1.9346, 2.5527],\n",
       "        [1.9346, 2.9159, 3.2304],\n",
       "        [2.5527, 3.2304, 5.3240]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.rand(m)\n",
    "(C_alt @ weights).transpose(-1, -2) @ weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1402)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((C_alt[0, :, 0, :] @ weights) * weights).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2304)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((C_alt[1, :, 2, :] @ weights) * weights).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing outputs is also easy\n",
    "\n",
    "(straightforward to do this with more than one elements of the outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.3130, 1.8746, 2.4631],\n",
       "        [1.8746, 2.2579, 1.6523],\n",
       "        [2.4631, 1.6523, 3.7077]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_alt[:, 1, :, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, we can have MTMVN themselves be indexable - if we have the external API assume that the shape is `batch_shape x n x m`, then doing `mtmvn[:4, :]` would access all outputs of the first four data points. Similarly, `mtmvn[0, ..., 2:]` would extract the mtmvn across all datapoints of the first batch element for all but the first outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.distributions import MultivariateNormal, MultitaskMultivariateNormal\n",
    "\n",
    "mean = torch.rand(2, 4)\n",
    "covar = make_rand_covar(4, batch_shape=(2,))\n",
    "mvn = MultivariateNormal(mean, covar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.2598, 1.2003, 1.2292, 0.9164],\n",
       "        [1.2003, 1.7207, 0.9716, 0.7842],\n",
       "        [1.2292, 0.9716, 1.9955, 0.6534],\n",
       "        [0.9164, 0.7842, 0.6534, 1.0543]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvn[-1].covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.2598, 1.2003, 1.2292, 0.9164],\n",
       "        [1.2003, 1.7207, 0.9716, 0.7842],\n",
       "        [1.2292, 0.9716, 1.9955, 0.6534],\n",
       "        [0.9164, 0.7842, 0.6534, 1.0543]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covar[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.2289, 1.1750],\n",
       "         [1.1750, 2.3230]],\n",
       "\n",
       "        [[1.9955, 0.6534],\n",
       "         [0.6534, 1.0543]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvn[:, -2:].covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.2289, 1.1750],\n",
       "         [1.1750, 2.3230]],\n",
       "\n",
       "        [[1.9955, 0.6534],\n",
       "         [0.6534, 1.0543]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covar[:, -2:, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtmean = torch.rand(4, 2)\n",
    "mtcovar = make_rand_covar(8)\n",
    "mtmvn = MultitaskMultivariateNormal(mtmean, mtcovar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4372, 0.5764],\n",
       "        [0.4178, 0.2967],\n",
       "        [0.3096, 0.2036],\n",
       "        [0.1308, 0.0618]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This fails - we want to enable this easily with the new representation\n",
    "# mtmvn[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing independet outputs\n",
    "\n",
    "Here we can just store the `m` individual `n x n` blocks as a `m x n x n` tensor, no need to store the cross covariances.\n",
    "\n",
    "We could also think of the case where we have independence across points, and only inter-task correlation. This will typically not be the case though, so we can punt on this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2450, 0.7732, 0.4257, 0.0000, 0.0000, 0.0000],\n",
       "        [0.7732, 2.5714, 1.7067, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4257, 1.7067, 2.0056, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 2.3348, 0.7860, 1.4855],\n",
       "        [0.0000, 0.0000, 0.0000, 0.7860, 1.1482, 1.0489],\n",
       "        [0.0000, 0.0000, 0.0000, 1.4855, 1.0489, 1.8948]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpytorch.lazy import BlockDiagLazyTensor\n",
    "\n",
    "C_indep = torch.stack([make_rand_covar(n) for _ in range(m)])\n",
    "\n",
    "# using the lazy here will speed up matrix operations\n",
    "BlockDiagLazyTensor(C_indep).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.2450, 0.7732, 0.4257],\n",
       "         [0.7732, 2.5714, 1.7067],\n",
       "         [0.4257, 1.7067, 2.0056]],\n",
       "\n",
       "        [[2.3348, 0.7860, 1.4855],\n",
       "         [0.7860, 1.1482, 1.0489],\n",
       "         [1.4855, 1.0489, 1.8948]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_indep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2450, 0.7732, 0.4257, 0.0000, 0.0000, 0.0000],\n",
       "        [0.7732, 2.5714, 1.7067, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4257, 1.7067, 2.0056, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 2.3348, 0.7860, 1.4855],\n",
       "        [0.0000, 0.0000, 0.0000, 0.7860, 1.1482, 1.0489],\n",
       "        [0.0000, 0.0000, 0.0000, 1.4855, 1.0489, 1.8948]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to construct the full matrix (we generally don't want to do this!) we can just do\n",
    "torch.block_diag(*C_indep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can also allow arbitrary order in the construction...\n",
    "\n",
    "### ... so long as we have a consistent internal representation\n",
    "\n",
    "The following orders are admissible (`n` is the number of points, `t` is the number tasks):\n",
    "\n",
    "```\n",
    "nntt\n",
    "ntnt\n",
    "nttn\n",
    "ttnn\n",
    "tntn\n",
    "tnnt\n",
    "\n",
    "nnt\n",
    "ntt\n",
    "ntn\n",
    "ttn\n",
    "tnt\n",
    "tnn\n",
    "```\n",
    "\n",
    "So basically we have the set \n",
    "```\n",
    "nnt\n",
    "ntt\n",
    "ntn\n",
    "ttn\n",
    "tnt\n",
    "tnn\n",
    "```\n",
    "\n",
    "and then the whole set of admissible combinations we get by combining this wiht the set we get by post-pending with the single letter (we could pre-pend too but that would just generate duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know this is admissible. We'd like to store things consistently internally. There are four options:\n",
    "\n",
    "- no independence -> can standardize to `n x t x n x t`\n",
    "- cross-task independence only -> can standardize to `t x n x n`\n",
    "- cross-point independence only -> can standardize to `n x t x t`\n",
    "- cross-task AND cross-point independence: This is trivial -> can standardize to `n x t` (just marginal variances)\n",
    "\n",
    "**For now we focus on the first two cases**, we can deal with the other ones later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.distributions.multioutput_multivariate_normal import MultioutputMultivariateNormal, NormalizedOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_b = torch.randn(b, n, m)\n",
    "mtmvn = MultioutputMultivariateNormal(mean=mean_b, covariance=C_alt_b, order=(\"n\" ,\"m\", \"n\", \"m\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultioutputMultivariateNormal(batch_shape=(2,), n=3, m=2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn.mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn.variance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn.rsample(torch.Size([4])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-10.2001,  -8.4040])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn.log_prob(mtmvn.mean + torch.randn_like(mtmvn.mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultioutputMultivariateNormal(n=3, m=2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select batch <- this should probably return an un-batched MOMVN\n",
    "mtmvn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultioutputMultivariateNormal(batch_shape=(2,), n=3, m=2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select range of batches\n",
    "mtmvn[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultivariateNormal(batch_shape=(2,), n=2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select data point <- should this return a MOMVN or just a batched MVN? batched MVN seems most logical\n",
    "mtmvn[..., 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultioutputMultivariateNormal(batch_shape=(2,), n=2, m=2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select range of data points\n",
    "mtmvn[..., :2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultivariateNormal(batch_shape=(2,), n=3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select output <- this should definitely return just a MVN\n",
    "mtmvn[..., 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultioutputMultivariateNormal(batch_shape=(2,), n=3, m=2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select range of outputs\n",
    "mtmvn[..., :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultivariateNormal(n=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mixed indexing select specific data point and output form specific batch\n",
    "# ^this is just a single Normal - how to interpret?\n",
    "mtmvn[0, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_indep_b = torch.stack([C_indep, C_indep + 1])\n",
    "\n",
    "mtmvn_indep = MultioutputMultivariateNormal(mean=mean_b, covariance=C_indep_b, order=(\"m\", \"n\", \"n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3, 3])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_indep_b.shape  # batch_shape x m x n x n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultioutputMultivariateNormal(batch_shape=(2,), n=3, m=2, independent outputs)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn_indep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn_indep.mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn_indep.variance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3, 2])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn_indep.rsample(torch.Size([4])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-23.9029,  -9.9000])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn_indep.log_prob(mtmvn_indep.mean + torch.randn_like(mtmvn_indep.mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultioutputMultivariateNormal(batch_shape=(2,), n=3, m=2, independent outputs)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn_indep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultioutputMultivariateNormal(n=3, m=2, independent outputs)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn_indep[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultivariateNormal(batch_shape=(2,), n=3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn_indep[..., :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultivariateNormal(batch_shape=(2,), n=2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn_indep[..., 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kronecker product structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.lazy import KroneckerProductLazyTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_shape = torch.Size([2])\n",
    "\n",
    "Kn = make_rand_covar(n, batch_shape)\n",
    "Km = make_rand_covar(m, batch_shape)\n",
    "\n",
    "covar = KroneckerProductLazyTensor(Km, Kn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.1333, 0.2893, 0.7803],\n",
       "         [0.2893, 1.1635, 0.5701],\n",
       "         [0.7803, 0.5701, 1.8817]],\n",
       "\n",
       "        [[1.5586, 0.5207, 0.9835],\n",
       "         [0.5207, 2.0579, 1.0481],\n",
       "         [0.9835, 1.0481, 1.4063]]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5969, 0.0491],\n",
       "         [0.0491, 0.8590]],\n",
       "\n",
       "        [[0.6028, 0.0862],\n",
       "         [0.0862, 1.5217]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6764, 0.1727, 0.4658, 0.0557, 0.0142, 0.0383],\n",
       "         [0.1727, 0.6945, 0.3403, 0.0142, 0.0572, 0.0280],\n",
       "         [0.4658, 0.3403, 1.1232, 0.0383, 0.0280, 0.0924],\n",
       "         [0.0557, 0.0142, 0.0383, 0.9734, 0.2485, 0.6703],\n",
       "         [0.0142, 0.0572, 0.0280, 0.2485, 0.9995, 0.4897],\n",
       "         [0.0383, 0.0280, 0.0924, 0.6703, 0.4897, 1.6163]],\n",
       "\n",
       "        [[0.9396, 0.3139, 0.5929, 0.1343, 0.0449, 0.0847],\n",
       "         [0.3139, 1.2406, 0.6318, 0.0449, 0.1773, 0.0903],\n",
       "         [0.5929, 0.6318, 0.8478, 0.0847, 0.0903, 0.1212],\n",
       "         [0.1343, 0.0449, 0.0847, 2.3717, 0.7923, 1.4967],\n",
       "         [0.0449, 0.1773, 0.0903, 0.7923, 3.1316, 1.5949],\n",
       "         [0.0847, 0.0903, 0.1212, 1.4967, 1.5949, 2.1401]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covar.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6764, 0.1727, 0.4658, 0.0557, 0.0142, 0.0383],\n",
       "         [0.1727, 0.6945, 0.3403, 0.0142, 0.0572, 0.0280],\n",
       "         [0.4658, 0.3403, 1.1232, 0.0383, 0.0280, 0.0924],\n",
       "         [0.0557, 0.0142, 0.0383, 0.9734, 0.2485, 0.6703],\n",
       "         [0.0142, 0.0572, 0.0280, 0.2485, 0.9995, 0.4897],\n",
       "         [0.0383, 0.0280, 0.0924, 0.6703, 0.4897, 1.6163]],\n",
       "\n",
       "        [[0.9396, 0.3139, 0.5929, 0.1343, 0.0449, 0.0847],\n",
       "         [0.3139, 1.2406, 0.6318, 0.0449, 0.1773, 0.0903],\n",
       "         [0.5929, 0.6318, 0.8478, 0.0847, 0.0903, 0.1212],\n",
       "         [0.1343, 0.0449, 0.0847, 2.3717, 0.7923, 1.4967],\n",
       "         [0.0449, 0.1773, 0.0903, 0.7923, 3.1316, 1.5949],\n",
       "         [0.0847, 0.0903, 0.1212, 1.4967, 1.5949, 2.1401]]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can construct the full tensor from the kronecker product (we DON'T want to do this)\n",
    "\n",
    "Dense = Km.unsqueeze(-1).unsqueeze(-1) * Kn.unsqueeze(-3).unsqueeze(-3).expand(*Km.shape, *Kn.shape[-2:])\n",
    "Dense.permute(0, 1, 3, 2, 4).reshape(*Km.shape[:-2], m*n, m*n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
